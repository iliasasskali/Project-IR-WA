{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/iliasasskali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "from array import array\n",
    "import math\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "\n",
    "import gensim.downloader as api \n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.manifold import TSNE\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets in the dataset: 2399\n"
     ]
    }
   ],
   "source": [
    "# Read json and store the text of each tweet into a list\n",
    "def read_json(docs_path):\n",
    "    with open(docs_path) as fp:\n",
    "        lines = json.load(fp)\n",
    "\n",
    "    print(\"Total number of tweets in the dataset: {}\".format(len(lines)))\n",
    "    return lines\n",
    "\n",
    "docs_path = 'inputs/dataset_tweets_WHO.txt'\n",
    "lines = read_json(docs_path)\n",
    "\n",
    "tweets = []\n",
    "for tweetId in lines:\n",
    "    tweets.append(lines[str(tweetId)][\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "\n",
    "url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "\n",
    "def remove_urls(line):\n",
    "    return url_pattern.sub(r'', line)\n",
    "\n",
    "def remove_emojis(line):\n",
    "    return emoji_pattern.sub(r'', line)\n",
    "\n",
    "def build_terms(line):\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    line = line.encode(\"ascii\", \"ignore\") # Remove unicode characters\n",
    "    line = line.decode()\n",
    "    line = line.lower() ## Transform to lowercase\n",
    "    line = remove_emojis(line) ## Remove emojis, before tokenizing to delete emojis not separated by space with a word\n",
    "    line = remove_urls(line) ## Remove urls\n",
    "    line = line.split() ## Tokenize the text to get a list of terms\n",
    "    line = [w for w in line if w not in stop_words]  ## eliminate the stopwords\n",
    "    line = [w for w in line if w[0]!='&' and w[-1]!=';'] ## Remove HTML symbol entity codes\n",
    "    line = [w.strip(string.punctuation.replace('#', '').replace('@', '')) for w in line] ## Remove punctuation except # and @\n",
    "    line = [stemmer.stem(w) for w in line if w!=''] ## perform stemming and remove empty words\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tweet:\n",
      "It's International Day for Disaster Risk Reduction\n",
      "\n",
      "#OpenWHO has launched a multi-tiered core curriculum to help equip you with the competencies needed to work within public health emergency response.\n",
      "\n",
      "Start learning today &amp; be #Ready4Response:\n",
      "üëâ https://t.co/hBFFOF0xKL https://t.co/fgZY22RWuS\n",
      "\n",
      "Processed tweet:\n",
      "['intern', 'day', 'disast', 'risk', 'reduct', '#openwho', 'launch', 'multi-ti', 'core', 'curriculum', 'help', 'equip', 'compet', 'need', 'work', 'within', 'public', 'health', 'emerg', 'respons', 'start', 'learn', 'today', '#ready4respons']\n",
      "\n",
      "Original tweet:\n",
      "#COVID19 has shown how health emergencies and disasters affect entire communities ‚Äì especially those with weak health systems, and vulnerable populations like migrants, indigenous peoples, and those living in fragile humanitarian conditions. https://t.co/jpUQpnu0V1\n",
      "\n",
      "Processed tweet:\n",
      "['#covid19', 'shown', 'health', 'emerg', 'disast', 'affect', 'entir', 'commun', 'especi', 'weak', 'health', 'system', 'vulner', 'popul', 'like', 'migrant', 'indigen', 'peopl', 'live', 'fragil', 'humanitarian', 'condit']\n",
      "\n",
      "Original tweet:\n",
      "It's International Day for Disaster Risk Reduction\n",
      " \n",
      "To better respond to emergencies countries must:\n",
      "‚úÖ invest in health care systems\n",
      "‚úÖ achieve gender equity\n",
      "‚úÖ protect marginalised groups\n",
      "‚úÖ ensure ready &amp; equitable access to supplies\n",
      " \n",
      "A strong &amp; resilient health system is üîë https://t.co/5NALyjIymp\n",
      "\n",
      "Processed tweet:\n",
      "['intern', 'day', 'disast', 'risk', 'reduct', 'better', 'respond', 'emerg', 'countri', 'must', 'invest', 'health', 'care', 'system', 'achiev', 'gender', 'equiti', 'protect', 'marginalis', 'group', 'ensur', 'readi', 'equit', 'access', 'suppli', 'strong', 'resili', 'health', 'system']\n",
      "\n",
      "Original tweet:\n",
      "RT @WHOAFRO: Congratulations Algeriaüá©üáø!\n",
      "\n",
      "#Algeria is the 16th country in #Africa to reach the milestone of fully vaccinating 10% of its pop‚Ä¶\n",
      "\n",
      "Processed tweet:\n",
      "['rt', '@whoafro', 'congratul', 'algeria', '#algeria', '16th', 'countri', '#africa', 'reach', 'mileston', 'fulli', 'vaccin', '10', 'pop']\n",
      "\n",
      "Original tweet:\n",
      "RT @opsoms: Si est√° completamente vacunado üíâüíâ, ¬øa√∫n puede contraer COVID-19? \n",
      "\n",
      "üö® No importa si est√° vacunado o si todav√≠a est√° esperando, s‚Ä¶\n",
      "\n",
      "Processed tweet:\n",
      "['rt', '@opsom', 'si', 'est', 'completament', 'vacunado', 'pued', 'contraer', 'covid-19', 'importa', 'si', 'est', 'vacunado', 'si', 'todava', 'est', 'esperando']\n",
      "\n",
      "Original tweet:\n",
      "RT @WHOSEARO: Is your #information coming from a source, not verified? Do not share any further. üîé\n",
      "\n",
      "#CheckBeforeYouShare üëâüèΩ https://t.co/VR‚Ä¶\n",
      "\n",
      "Processed tweet:\n",
      "['rt', '@whosearo', '#inform', 'come', 'sourc', 'verifi', 'share', 'further', '#checkbeforeyoushar']\n",
      "\n",
      "Original tweet:\n",
      "RT @DrTedros: We must appreciate the role private sector has played in the #COVID19 response and the development of vaccines in the shortes‚Ä¶\n",
      "\n",
      "Processed tweet:\n",
      "['rt', '@drtedro', 'must', 'appreci', 'role', 'privat', 'sector', 'play', '#covid19', 'respons', 'develop', 'vaccin', 'short']\n",
      "\n",
      "Original tweet:\n",
      "RT @DrTedros: Humanity is failing miserably with vaccine injustice. Debating whether intellectual property rights should be waived in such‚Ä¶\n",
      "\n",
      "Processed tweet:\n",
      "['rt', '@drtedro', 'human', 'fail', 'miser', 'vaccin', 'injustic', 'debat', 'whether', 'intellectu', 'properti', 'right', 'waiv']\n",
      "\n",
      "Original tweet:\n",
      "RT @DrTedros: #COVID19 has had a major impact on people‚Äôs #mentalhealth. Thanks, @DoctorJas of @WHOPhilippines, for your dedicated work to‚Ä¶\n",
      "\n",
      "Processed tweet:\n",
      "['rt', '@drtedro', '#covid19', 'major', 'impact', 'peopl', '#mentalhealth', 'thank', '@doctorja', '@whophilippin', 'dedic', 'work']\n",
      "\n",
      "Original tweet:\n",
      "RT @DrTedros: Broad administration of booster doses is unfair, unjust &amp; immoral at a time when #healthworkers &amp; at most risk people in many‚Ä¶\n",
      "\n",
      "Processed tweet:\n",
      "['rt', '@drtedro', 'broad', 'administr', 'booster', 'dose', 'unfair', 'unjust', 'immor', 'time', '#healthwork', 'risk', 'peopl', 'mani']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute to see first 10 original and processed tweets\n",
    "for tweet in tweets[:10]:\n",
    "    print(\"Original tweet:\\n\" + tweet + \"\\n\")\n",
    "    print(\"Processed tweet:\\n\" + str(build_terms(tweet)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 2: INDEXING AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Inverted index:\n",
    "def create_index(lines):\n",
    "    \"\"\"\n",
    "    Implement the inverted index\n",
    "    \n",
    "    Argument:\n",
    "    lines -- collection of json tweets\n",
    "    \n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of documents where these keys appears in (and the positions) as values.\n",
    "    \"\"\"\n",
    "    index = defaultdict(list)\n",
    "    tweet_index = {}  # dictionary to map tweet ids (starting from 0) to their info\n",
    "    for tweetId in lines:  # lines contain all tweets, whith the id as key\n",
    "        full_tweet = lines[str(tweetId)]\n",
    "        \n",
    "        tweet_id = full_tweet[\"id\"] # id \n",
    "        tweet = full_tweet[\"full_text\"] # Tweet\n",
    "        username = full_tweet[\"user\"][\"screen_name\"] # Username\n",
    "        date = full_tweet[\"created_at\"] # Date\n",
    "        hashtags = full_tweet[\"entities\"][\"hashtags\"] # Hashtags\n",
    "        likes = full_tweet[\"favorite_count\"] # Likes\n",
    "        retweets = full_tweet[\"retweet_count\"] # Retweets\n",
    "        url = f\"https://twitter.com/{username}/status/{tweet_id}\" # Url\n",
    "        terms = build_terms(tweet)\n",
    "        \n",
    "        # Store tweet info in the dictonary to retrieve it faster when searching\n",
    "        tweet_index[tweetId] = {}\n",
    "        tweet_index[tweetId][\"tweet\"] = tweet\n",
    "        tweet_index[tweetId][\"username\"] = username\n",
    "        tweet_index[tweetId][\"date\"] = date\n",
    "        tweet_index[tweetId][\"hashtags\"] = hashtags\n",
    "        tweet_index[tweetId][\"likes\"] = likes\n",
    "        tweet_index[tweetId][\"retweets\"] = retweets\n",
    "        tweet_index[tweetId][\"url\"] = url\n",
    "\n",
    "        current_page_index = {}\n",
    "\n",
    "        for position, term in enumerate(terms): # Loop over all terms\n",
    "            try:\n",
    "                # if the term is already in the index for the current page (current_page_index)\n",
    "                # append the position to the corresponding list\n",
    "                current_page_index[term][1].append(position)  \n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                current_page_index[term]=[tweetId, array('I',[position])] \n",
    "            \n",
    "        # Merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "                            \n",
    "    return index, tweet_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create the index: 1.87 seconds\n",
      "Index results for the term 'researcher': []\n",
      "\n",
      "First 10 Index results for the term 'research': \n",
      "[['0', array('I', [0])], ['2', array('I', [0])], ['35', array('I', [1])], ['262', array('I', [0])], ['273', array('I', [0])], ['277', array('I', [0])], ['278', array('I', [1])], ['280', array('I', [1])], ['299', array('I', [0])], ['338', array('I', [0])]]\n"
     ]
    }
   ],
   "source": [
    "# Index creation and test\n",
    "start_time = time.time()\n",
    "index, tweet_index = create_index(lines)\n",
    "print(\"Total time to create the index: {} seconds\".format(np.round(time.time() - start_time, 2)))\n",
    "\n",
    "print(\"Index results for the term 'researcher': {}\\n\".format(index['international']))\n",
    "print(\"First 10 Index results for the term 'research': \\n{}\".format(index['intern'][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, index):\n",
    "    \"\"\"\n",
    "    The output is the list of documents that contain any of the query terms. \n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"                        \n",
    "            term_docs=[posting[0] for posting in index[term]]\n",
    "            # docs = docs Union term_docs\n",
    "            docs = docs.union(term_docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query (i.e.: Computer Science):\n",
      "\n",
      "\n",
      "======================\n",
      "Sample of 10 results out of 3 for the searched query:\n",
      "\n",
      "page_id= 61 - tweet: RT @WHOPhilippines: Vaccines can‚Äôt stop #COVID19 alone, but by doing it all we can help protect ourselves and our loved ones against COVID-‚Ä¶\n",
      "page_id= 200 - tweet: üÜï WHO clinical case definition for post #COVID19 condition, also called 'long COVID' https://t.co/WoiLcwsgJX https://t.co/Z0olrHlWPC\n",
      "page_id= 1561 - tweet: If you have recovered from #COVID19 but are still experiencing certain symptoms you could have post COVID-19 condition or \"long COVID\". What are these symptoms? How long do they last and are there any treatment options? Dr @diazjv explains in #ScienceIn5 ‚¨áÔ∏è https://t.co/vtDiBhZsJE\n"
     ]
    }
   ],
   "source": [
    "# Test by inserting a query\n",
    "print(\"Insert your query (i.e.: Computer Science):\\n\")\n",
    "query = input()\n",
    "docs = search(query, index)\n",
    "top = 10\n",
    "\n",
    "print(\"\\n======================\\nSample of {} results out of {} for the searched query:\\n\".format(top, len(docs)))\n",
    "for d_id in docs[:top]:\n",
    "    print(\"page_id= {} - tweet: {}\".format(d_id, tweet_index[d_id][\"tweet\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "Sample of 3 results out of 236 for the query covid pandemic:\n",
      "\n",
      "page_id= 963 - tweet: @DrTedros @IMFNews @WorldBank @wto @G7 \"Even as we respond to the #COVID19 pandemic, we must learn the lessons it's teaching us. One of the most clear is the need for new, powerful systems &amp; tools for üåç surveillance, to collect, analyse &amp; disseminate data on outbreaks with the potential to become pandemics\"-@DrTedros\n",
      "page_id= 1087 - tweet: \"Most recently, the @g20org established a High-Level Independent Panel on Financing the Global Commons for Pandemic Preparedness and Response.\"-@DrTedros \n",
      "https://t.co/5U2cYU5mDm\n",
      "page_id= 2013 - tweet: The Emergency Committee on #COVID19 reconvenes every 3 months to evaluate the evolution of the pandemic &amp; make recommendations to WHO &amp; countries on how to respond to the Public Health Emergency of International Concern.\n",
      "\n",
      "Previous recommendations: https://t.co/cA4FCWWUqJ https://t.co/bmkZN64X50\n",
      "\n",
      "======================\n",
      "Sample of 3 results out of 78 for the query international disaster:\n",
      "\n",
      "page_id= 1141 - tweet: \"That‚Äôs why there is now an emerging global consensus for the idea of an international treaty or other legal instrument, to provide the basis for improved international cooperation to prepare for, detect and respond to epidemics and pandemics.\"-@DrTedros at #RC71AFRO\n",
      "page_id= 2013 - tweet: The Emergency Committee on #COVID19 reconvenes every 3 months to evaluate the evolution of the pandemic &amp; make recommendations to WHO &amp; countries on how to respond to the Public Health Emergency of International Concern.\n",
      "\n",
      "Previous recommendations: https://t.co/cA4FCWWUqJ https://t.co/bmkZN64X50\n",
      "page_id= 898 - tweet: It's the International Day of Clean Air for Blue Skies\n",
      " \n",
      "#AirPollution kills an estimated 7‚É£ million people every year around the üåéüåçüåè\n",
      " \n",
      "To save lives and achieve #HealthForAll, let's align our efforts and claim the right to clean air. https://t.co/YrbJkvjOUT\n",
      "\n",
      "======================\n",
      "Sample of 3 results out of 16 for the query ritmo de vacunacion:\n",
      "\n",
      "page_id= 710 - tweet: RT @OMS_Afrique: BONNE NOUVELLE ! ü•≥\n",
      "\n",
      "La #Guin√©eüá¨üá≥ a d√©clar√© la fin de la flamb√©e de maladie √† virus #Marburg aujourd'hui ! \n",
      "\n",
      "Au total, un s‚Ä¶\n",
      "page_id= 49 - tweet: RT @ONU_es: La depresi√≥n le puede suceder a cualquiera.\n",
      "No es un signo de debilidad, es una enfermedad.\n",
      "Tiene tratamiento.\n",
      "\n",
      "En este #D√≠aDeL‚Ä¶\n",
      "page_id= 1320 - tweet: RT @PAHOemergencies: On estime un grand nombre de personnes touch√©es, de d√©c√®s et de d√©g√¢ts suite au s√©isme de 7,2 qui s'est produit ce mat‚Ä¶\n",
      "\n",
      "======================\n",
      "Sample of 3 results out of 18 for the query percentage de hospitalizados:\n",
      "\n",
      "page_id= 710 - tweet: RT @OMS_Afrique: BONNE NOUVELLE ! ü•≥\n",
      "\n",
      "La #Guin√©eüá¨üá≥ a d√©clar√© la fin de la flamb√©e de maladie √† virus #Marburg aujourd'hui ! \n",
      "\n",
      "Au total, un s‚Ä¶\n",
      "page_id= 49 - tweet: RT @ONU_es: La depresi√≥n le puede suceder a cualquiera.\n",
      "No es un signo de debilidad, es una enfermedad.\n",
      "Tiene tratamiento.\n",
      "\n",
      "En este #D√≠aDeL‚Ä¶\n",
      "page_id= 1320 - tweet: RT @PAHOemergencies: On estime un grand nombre de personnes touch√©es, de d√©c√®s et de d√©g√¢ts suite au s√©isme de 7,2 qui s'est produit ce mat‚Ä¶\n",
      "\n",
      "======================\n",
      "Sample of 3 results out of 607 for the query mental health:\n",
      "\n",
      "page_id= 868 - tweet: @DrTedros \"Today, the #DRC declared an outbreak of #meningitis in the north-eastern Tshopo Province, with 261 suspected cases and 129 deaths reported. Health authorities have deployed an initial emergency team, and WHO is supporting the response\"-@DrTedros \n",
      "https://t.co/PpbZcTe483\n",
      "page_id= 907 - tweet: RT @DrTedros: Had good meeting with #Russia Minister of Health Mikhail Murashko on @WHO-üá∑üá∫ collaboration on the #COVID19 response &amp; strengt‚Ä¶\n",
      "page_id= 1036 - tweet: WHO releases new compendium of innovative health technologies that can be used in low-resource settings for #COVID19 and other priority diseases.\n",
      "‚ñ∂Ô∏è https://t.co/SwVaGP6Hr5 https://t.co/saYg2J5xNK\n"
     ]
    }
   ],
   "source": [
    "# 2. Make a proposal of 5 queries that will be used to evaluate your search engine\n",
    "queries = [\n",
    "    \"covid pandemic\",\n",
    "    \"international disaster\",\n",
    "    \"ritmo de vacunacion\",\n",
    "    \"percentage de hospitalizados\",\n",
    "    \"mental health\"\n",
    "]\n",
    "top = 3 # Number of tweets to show\n",
    "for query in queries:\n",
    "    docs = search(query, index) # obtain the tweets resulting of such query\n",
    "    print(\"\\n======================\\nSample of {} results out of {} for the query {}:\\n\".format(top, len(docs), query))\n",
    "    for d_id in docs[:top]:\n",
    "        print(\"page_id= {} - tweet: {}\".format(d_id, tweet_index[d_id][\"tweet\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Apply a TF-IDF ranking to your results.\n",
    "def create_index_tfidf(lines, num_documents):\n",
    "    \"\"\"\n",
    "    Implement the inverted index and compute tf, df and idf\n",
    "    \n",
    "    Argument:\n",
    "    lines -- collection of tweets\n",
    "    num_documents -- total number of tweets\n",
    "    \n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of document these keys appears in (and the positions) as values.\n",
    "    tf - normalized term frequency for each term in each document\n",
    "    df - number of documents each term appear in\n",
    "    idf - inverse document frequency of each term\n",
    "    \"\"\"\n",
    "\n",
    "    index = defaultdict(list)\n",
    "    tf = defaultdict(list)  # term frequencies of terms in documents\n",
    "    df = defaultdict(int)  # document frequencies of terms in the corpus\n",
    "    tweet_index = defaultdict(str)\n",
    "    idf = defaultdict(float)\n",
    "\n",
    "    for tweetId in lines:\n",
    "        full_tweet = lines[str(tweetId)]\n",
    "        \n",
    "        tweet_id = full_tweet[\"id\"] # id \n",
    "        tweet = full_tweet[\"full_text\"] # Tweet\n",
    "        username = full_tweet[\"user\"][\"screen_name\"] # Username\n",
    "        date = full_tweet[\"created_at\"] # Date\n",
    "        hashtags = full_tweet[\"entities\"][\"hashtags\"] # Hashtags\n",
    "        likes = full_tweet[\"favorite_count\"] # Likes\n",
    "        retweets = full_tweet[\"retweet_count\"] # Retweets\n",
    "        url = f\"https://twitter.com/{username}/status/{tweet_id}\" # Url\n",
    "        terms = build_terms(tweet)\n",
    "        \n",
    "        # Store tweet info in the dictonary to retrieve it faster when searching\n",
    "        tweet_index[tweetId] = {}\n",
    "        tweet_index[tweetId][\"tweet\"] = tweet\n",
    "        tweet_index[tweetId][\"username\"] = username\n",
    "        tweet_index[tweetId][\"date\"] = date\n",
    "        tweet_index[tweetId][\"hashtags\"] = hashtags\n",
    "        tweet_index[tweetId][\"likes\"] = likes\n",
    "        tweet_index[tweetId][\"retweets\"] = retweets\n",
    "        tweet_index[tweetId][\"url\"] = url\n",
    "\n",
    "        current_page_index = {}\n",
    "        for position, term in enumerate(terms):\n",
    "            try:\n",
    "                # if the term is already in the dict append the position to the corresponding list\n",
    "                current_page_index[term][1].append(position)\n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                current_page_index[term]=[tweetId, array('I',[position])]\n",
    "\n",
    "        # Normalize term frequencies\n",
    "        norm = 0\n",
    "        for term, posting in current_page_index.items():\n",
    "            norm += len(posting[1]) ** 2\n",
    "        norm = math.sqrt(norm)\n",
    "\n",
    "        # Calculate the tf and df weights\n",
    "        for term, posting in current_page_index.items():\n",
    "            tf[term].append(np.round(len(posting[1])/norm,4))\n",
    "            df[term] += 1 # increment DF for current term\n",
    "\n",
    "        # Merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "\n",
    "        # Compute IDF following the formula (3) above. HINT: use np.log\n",
    "        for term in df:\n",
    "            idf[term] = np.round(np.log(float(num_documents/df[term])), 4)\n",
    "\n",
    "    return index, tf, df, idf, tweet_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create the index: 116.18 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "num_documents = len(lines)\n",
    "index, tf, df, idf, tweet_index = create_index_tfidf(lines, num_documents)\n",
    "print(\"Total time to create the index: {} seconds\" .format(np.round(time.time() - start_time, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank_documents(terms, docs, index, idf, tf, tweet_index):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "    \n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    tweet_index -- mapping between page id and page title\n",
    "    \n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms))\n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query. \n",
    "\n",
    "    query_norm = sum(query_terms_count.values())\n",
    "    for termIndex, term in enumerate(terms):  # termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex] = query_terms_count[term] / query_norm * idf[term] \n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):           \n",
    "            if doc in docs:\n",
    "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term]\n",
    "\n",
    "    # Calculate the score of each doc \n",
    "    # compute the cosine similarity between queyVector and each docVector:\n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    \n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "\n",
    "    if len(result_docs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "        query = input()\n",
    "        docs = search_tf_idf(query, index)\n",
    "\n",
    "    return result_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_tf_idf(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms. \n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"                        \n",
    "            term_docs=[posting[0] for posting in index[term]]\n",
    "            \n",
    "            # docs = docs Union term_docs\n",
    "            docs = docs.union(term_docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = rank_documents(query, docs, index, idf, tf, tweet_index)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query (i.e.: Computer Science):\n",
      "\n",
      "\n",
      "======================\n",
      "Top 10 results out of 3 for the searched query:\n",
      "\n",
      "page_id= 200 - page_title: {'tweet': \"üÜï WHO clinical case definition for post #COVID19 condition, also called 'long COVID' https://t.co/WoiLcwsgJX https://t.co/Z0olrHlWPC\", 'username': 'WHO', 'date': 'Thu Oct 07 12:28:10 +0000 2021', 'hashtags': [{'text': 'COVID19', 'indices': [40, 48]}], 'likes': 723, 'retweets': 373, 'url': 'https://twitter.com/WHO/status/1446089970758860801'}\n",
      "page_id= 61 - page_title: {'tweet': 'RT @WHOPhilippines: Vaccines can‚Äôt stop #COVID19 alone, but by doing it all we can help protect ourselves and our loved ones against COVID-‚Ä¶', 'username': 'WHO', 'date': 'Mon Oct 11 04:39:10 +0000 2021', 'hashtags': [{'text': 'COVID19', 'indices': [40, 48]}], 'likes': 0, 'retweets': 71, 'url': 'https://twitter.com/WHO/status/1447421491428143106'}\n",
      "page_id= 1561 - page_title: {'tweet': 'If you have recovered from #COVID19 but are still experiencing certain symptoms you could have post COVID-19 condition or \"long COVID\". What are these symptoms? How long do they last and are there any treatment options? Dr @diazjv explains in #ScienceIn5 ‚¨áÔ∏è https://t.co/vtDiBhZsJE', 'username': 'WHO', 'date': 'Mon Aug 02 11:38:39 +0000 2021', 'hashtags': [{'text': 'COVID19', 'indices': [27, 35]}, {'text': 'ScienceIn5', 'indices': [243, 254]}], 'likes': 277, 'retweets': 154, 'url': 'https://twitter.com/WHO/status/1422159909957869572'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Insert your query (i.e.: Computer Science):\\n\")\n",
    "query = input()\n",
    "ranked_docs = search_tf_idf(query, index)\n",
    "top = 10\n",
    "\n",
    "print(\"\\n======================\\nTop {} results out of {} for the searched query:\\n\".format(top, len(ranked_docs)))\n",
    "for d_id in ranked_docs[:top]:\n",
    "    print(\"page_id= {} - page_title: {}\".format(d_id, tweet_index[d_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth of our dataset is composed of 5 Relevance Levels: [0.0, 1.0, 2.0, 3.0, 4.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>predicted_relevance</th>\n",
       "      <th>y_true</th>\n",
       "      <th>bin_y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.637926</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.824241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.358856</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.096755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.268338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_id  doc_id  predicted_relevance  y_true  bin_y_true\n",
       "0     0       0            -0.637926     2.0           1\n",
       "1     0       1            -0.824241     1.0           0\n",
       "2     0       2            -1.358856     3.0           1\n",
       "3     0       3            -0.096755     1.0           0\n",
       "4     0       4            -1.268338     0.0           0"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = pd.read_csv(\"inputs/test_predictions.csv\")\n",
    "search_results.head()\n",
    "print(\"The ground truth of our dataset is composed of {} Relevance Levels: {}\" .format(len(search_results[\"y_true\"].unique()), sorted(search_results[\"y_true\"].unique())))\n",
    "search_results[\"bin_y_true\"] = np.where(search_results[\"y_true\"] >= 2.0, 1, 0)\n",
    "search_results.head()\n",
    "search_results[\"bin_y_true\"] = search_results[\"y_true\"].apply(lambda y: 1 if y >=2 else 0)\n",
    "search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(y_true, y_score, k=10):\n",
    "    '''    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "    \n",
    "    '''    \n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    relevant = sum(y_true == 1)\n",
    "    return float(relevant) / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Precision@5: 0.6\n",
      "\n",
      "\n",
      "Check on the dataset sorted by score:\n",
      "\n",
      "==> Precision@3: 0.6666666666666666\n",
      "\n",
      "\n",
      "Check on the dataset sorted by score:\n",
      "\n",
      "==> Precision@10: 0.6\n",
      "\n",
      "\n",
      "Check on the dataset sorted by score:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>predicted_relevance</th>\n",
       "      <th>y_true</th>\n",
       "      <th>bin_y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>1.705258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>1.116369</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.096797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1.084367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.082985</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1.081464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1.075457</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>1.063326</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1.016901</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0.906784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     q_id  doc_id  predicted_relevance  y_true  bin_y_true\n",
       "88      0      88             1.705258     2.0           1\n",
       "114     0     114             1.116369     2.0           1\n",
       "63      0      63             1.096797     1.0           0\n",
       "34      0      34             1.084367     1.0           0\n",
       "86      0      86             1.082985     3.0           1\n",
       "47      0      47             1.081464     0.0           0\n",
       "55      0      55             1.075457     2.0           1\n",
       "76      0      76             1.063326     3.0           1\n",
       "17      0      17             1.016901     2.0           1\n",
       "58      0      58             0.906784     1.0           0"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for query 0\n",
    "\n",
    "current_query = 0\n",
    "current_query_res = search_results[search_results[\"q_id\"] == current_query] \n",
    "k=5\n",
    "\n",
    "print(\"==> Precision@{}: {}\\n\".format(k,\n",
    "                                precision_at_k(current_query_res[\"bin_y_true\"], current_query_res[\"predicted_relevance\"], k)))\n",
    "print(\"\\nCheck on the dataset sorted by score:\\n\")\n",
    "current_query_res.sort_values(\"predicted_relevance\", ascending=False).head(k)\n",
    "k=3\n",
    "print(\"==> Precision@{}: {}\\n\".format(k,\n",
    "                                precision_at_k(current_query_res[\"bin_y_true\"], current_query_res[\"predicted_relevance\"], k)))\n",
    "print(\"\\nCheck on the dataset sorted by score:\\n\")\n",
    "current_query_res.sort_values(\"predicted_relevance\", ascending=False).head(k)\n",
    "k=10\n",
    "print(\"==> Precision@{}: {}\\n\".format(k,\n",
    "                                precision_at_k(current_query_res[\"bin_y_true\"], current_query_res[\"predicted_relevance\"], k)))\n",
    "print(\"\\nCheck on the dataset sorted by score:\\n\")\n",
    "current_query_res.sort_values(\"predicted_relevance\", ascending=False).head(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_precision_at_k(y_true, y_score, k=10):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    average precision @k : float\n",
    "    '''\n",
    "    gtp = np.sum(y_true == 1) \n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])            \n",
    "    ## if all docs are not relevant\n",
    "    if gtp==0:\n",
    "        return 0\n",
    "    n_relevant_at_i = 0\n",
    "    prec_at_i = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1:\n",
    "            n_relevant_at_i +=1\n",
    "            prec_at_i += n_relevant_at_i/(i+1)\n",
    "    return prec_at_i/gtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5021658287937124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5021658287937125"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(avg_precision_at_k(np.array(current_query_res[\"bin_y_true\"]), np.array(current_query_res[\"predicted_relevance\"]), 150))\n",
    "from sklearn.metrics import average_precision_score\n",
    "k = 150\n",
    "temp = current_query_res.sort_values(\"predicted_relevance\", ascending=False).head(k)\n",
    "average_precision_score(np.array(temp[\"bin_y_true\"]), np.array(temp[\"predicted_relevance\"][:k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(search_res, k=10):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_res: search results dataset containing:\n",
    "        q_id: query id.\n",
    "        doc_id: document id.\n",
    "        predicted_relevance: relevance predicted through LightGBM.\n",
    "        y_true: actual score of the document for the query (ground truth).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean average precision @k : float\n",
    "    '''\n",
    "    avp = []\n",
    "    for q in search_res[\"q_id\"].unique(): #loop over all query id\n",
    "        curr_data = search_res[search_res[\"q_id\"] == q]  # select data for current query\n",
    "        avp.append(avg_precision_at_k(np.array(curr_data[\"bin_y_true\"]), np.array(curr_data[\"predicted_relevance\"]),k)) #append average precision for current query\n",
    "    return np.sum(avp)/len(avp) # return mean average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1752575969478396"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_k = map_at_k(search_results, 10)\n",
    "map_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr_at_k(y_true, y_score, k=10):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Reciprocal Rank for qurrent query\n",
    "    '''\n",
    "\n",
    "    order = np.argsort(y_score)[::-1] # get the list of indexes of the predicted score sorted in descending order.\n",
    "    y_true = np.take(y_true,order[:k]) # sort the actual relevance label of the documents based on predicted score(hint: np.take) and take first k.\n",
    "    if np.sum(y_true) == 0: # if there are not relevant doument return 0\n",
    "        return 0\n",
    "    return 1/(np.argmax(y_true == 1)+1) # hint: to get the position of the first relevant document use \"np.argmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([0,1,0,1,1])\n",
    "score = np.array([0.9, 0.5, 0.6, 0.7, 0.2])\n",
    "rr_at_k(y_true, score,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>predicted_relevance</th>\n",
       "      <th>y_true</th>\n",
       "      <th>bin_y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>0.115248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.046405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.404693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.493206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.701708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.755329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.802263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.827835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.836900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.878972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      q_id  doc_id  predicted_relevance  y_true  bin_y_true\n",
       "1067     8      52             0.115248     0.0           0\n",
       "1039     8      24            -0.046405     0.0           0\n",
       "1028     8      13            -0.404693     0.0           0\n",
       "1051     8      36            -0.493206     1.0           0\n",
       "1066     8      51            -0.701708     1.0           0\n",
       "1034     8      19            -0.755329     0.0           0\n",
       "1015     8       0            -0.802263     2.0           1\n",
       "1025     8      10            -0.827835     0.0           0\n",
       "1031     8      16            -0.836900     0.0           0\n",
       "1022     8       7            -0.878972     0.0           0"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_query = 8\n",
    "current_query_res = search_results[search_results[\"q_id\"] == current_query] \n",
    "current_query_res.sort_values(\"predicted_relevance\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1429"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(search_results[search_results['q_id'] == 8][\"bin_y_true\"])\n",
    "scores = np.array(search_results[search_results['q_id'] == 8][\"predicted_relevance\"])\n",
    "np.round(rr_at_k(labels, scores, 10),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr = {}\n",
    "for k in [3,5,10]:\n",
    "    RRs = []\n",
    "    for q in search_results['q_id'].unique(): # loop over all query ids\n",
    "        labels = np.array(search_results[search_results['q_id'] == q][\"bin_y_true\"]) # get labels for current query\n",
    "        scores = np.array(search_results[search_results['q_id'] == q][\"predicted_relevance\"]) # get predicted score for current query\n",
    "        RRs.append(rr_at_k(labels, scores, k)) # append RR for current query\n",
    "    mrr[k] = np.round(float(sum(RRs)/len(RRs)),4) # Mean RR at current k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(y_true, y_score,  k=10):\n",
    "    order = np.argsort(y_score)[::-1] # get the list of indexes of the predicted score sorted in descending order.\n",
    "    y_true = np.take(y_true, order[:k]) # sort the actual relevance label of the documents based on predicted score(hint: np.take) and take first k.\n",
    "    gain = 2 ** y_true - 1 # Compute gain (use formula 7 above)\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2) # Compute denominator\n",
    "    return np.sum(gain / discounts) #return dcg@k\n",
    "\n",
    "\n",
    "def ndcg_at_k(y_true, y_score, k=10):    \n",
    "    dcg_max = dcg_at_k(y_true, y_true, k)\n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    return np.round(dcg_at_k(y_true, y_score, k) / dcg_max,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg@10 for query with q_id=0: 0.4392\n"
     ]
    }
   ],
   "source": [
    "q_id = 0\n",
    "k = 10\n",
    "labels = np.array(search_results[search_results['q_id'] == q_id][\"y_true\"])\n",
    "scores = np.array(search_results[search_results['q_id'] == q_id][\"predicted_relevance\"])\n",
    "ndcg_k = np.round(ndcg_at_k(labels, scores, k),4)\n",
    "print(\"ndcg@{} for query with q_id={}: {}\".format(k,q_id,ndcg_k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ndcg@10: 0.4646\n"
     ]
    }
   ],
   "source": [
    "ndcgs = []\n",
    "k=10\n",
    "for q in search_results['q_id'].unique():\n",
    "    labels = np.array(search_results[search_results['q_id'] == q][\"y_true\"])\n",
    "    scores = np.array(search_results[search_results['q_id'] == q][\"predicted_relevance\"])\n",
    "    ndcgs.append(np.round(ndcg_at_k(labels, scores, k),4))\n",
    "\n",
    "avg_ndcg = np.round(float(sum(ndcgs)/len(ndcgs)),4)\n",
    "print(\"Average ndcg@{}: {}\".format(k,avg_ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# First time running this, it will take awhile (over 10 minutes depending on downloading speed)\n",
    "# The model (word2vec-google-news-300) is trained on Google News (about 100 billion words).\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\") # Load Word2Vec language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_representation(tweet):\n",
    "    \"\"\"\n",
    "    Represents a tweet as a vector computing the average of the word2vec representation of each word\n",
    "    input: tweet\n",
    "    output: vector representation of the tweet\n",
    "    \"\"\"\n",
    "    dim = len(word2vec_model['good'])\n",
    "    word_vectors = []\n",
    "    words = build_terms(tweet)\n",
    "    for word in words:\n",
    "        if word in word2vec_model:\n",
    "            word_vector = word2vec_model[word]\n",
    "            word_vectors.append(word_vector)\n",
    "        else:\n",
    "            word_vectors.append(np.zeros(dim))\n",
    "    if len(word_vectors) > 1:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0530599 ,  0.09318002, -0.03125   ,  0.        , -0.10986328,\n",
       "        0.09505208,  0.06656901, -0.02956645,  0.02246094, -0.08886719,\n",
       "       -0.13490804, -0.07177734, -0.00813802, -0.07128906,  0.0154012 ,\n",
       "        0.21354167, -0.05399577,  0.02539062,  0.11832682, -0.07967122,\n",
       "       -0.01072184, -0.05859375,  0.12207031, -0.13248698, -0.05196126,\n",
       "       -0.06066895, -0.05731201,  0.05823771, -0.16699219,  0.04231771,\n",
       "       -0.10441081, -0.17073568, -0.09391276,  0.06901042, -0.01928711,\n",
       "       -0.11865234, -0.02034505, -0.05834961,  0.03938802,  0.06738281,\n",
       "        0.01033529, -0.21419271, -0.14908854, -0.04573568,  0.04573568,\n",
       "       -0.19938151, -0.03808594, -0.09773763,  0.10611979,  0.18326823,\n",
       "       -0.08886719, -0.1546224 ,  0.0625    ,  0.06050618, -0.03430176,\n",
       "        0.07613118,  0.19889323, -0.07014974, -0.11751302, -0.03446452,\n",
       "       -0.03597005,  0.00179036, -0.10986328,  0.03938802,  0.01204427,\n",
       "        0.0534668 , -0.05989583, -0.11222331,  0.02880859,  0.04675293,\n",
       "       -0.13671875, -0.07336426,  0.00358073, -0.17740885, -0.25911458,\n",
       "        0.06608073,  0.14941406, -0.01216634, -0.04101562, -0.08447266,\n",
       "        0.07421875,  0.09602865, -0.05908203, -0.19935099, -0.04882812,\n",
       "        0.15917969,  0.02644857,  0.16536458,  0.18457031, -0.01066081,\n",
       "       -0.11523438, -0.16308594, -0.17415365,  0.04215495,  0.05501302,\n",
       "       -0.03011068,  0.1171875 ,  0.00195312,  0.26139323, -0.00089518,\n",
       "        0.09179688, -0.0929362 , -0.06380208, -0.23632812, -0.03190104,\n",
       "       -0.02319336, -0.04459635,  0.07161458, -0.02766927, -0.00369263,\n",
       "       -0.09863281,  0.00301107,  0.03238932, -0.18652344,  0.13053385,\n",
       "       -0.0016276 ,  0.12516276, -0.00488281,  0.15360514,  0.00260417,\n",
       "       -0.01627604, -0.26171875, -0.10791016, -0.15209961,  0.12752279,\n",
       "       -0.04956055, -0.02278646,  0.16178385,  0.09643555,  0.08333333,\n",
       "        0.02441406, -0.04427083, -0.19954427, -0.11214193,  0.04166667,\n",
       "        0.17122396, -0.15983073,  0.13785807,  0.1089681 ,  0.1266276 ,\n",
       "        0.06591797, -0.04740397, -0.06136068,  0.17325846, -0.01128133,\n",
       "        0.27734375,  0.03401693, -0.07739258, -0.0078125 , -0.10416667,\n",
       "        0.27929688,  0.01888021, -0.02571615,  0.05224609,  0.18717448,\n",
       "       -0.07617188, -0.00390625, -0.0625    ,  0.02347819,  0.05257161,\n",
       "        0.00805664,  0.13346354, -0.0223999 ,  0.12239583, -0.02197266,\n",
       "        0.11686198,  0.08426921,  0.06201172, -0.18457031,  0.15445964,\n",
       "        0.09236654,  0.1007487 ,  0.00455729,  0.18994141, -0.15981038,\n",
       "        0.04724121,  0.04744466, -0.14192708,  0.04492188, -0.16601562,\n",
       "       -0.13932292,  0.07609049,  0.01106771, -0.18717448, -0.12272135,\n",
       "        0.03827922, -0.04833984,  0.05371094, -0.08398438,  0.01114909,\n",
       "       -0.00553385, -0.00846354,  0.17057292,  0.07763672, -0.01123556,\n",
       "        0.0296224 ,  0.04492188, -0.10693359,  0.09179688,  0.09619141,\n",
       "        0.10970052,  0.03922526, -0.02832031,  0.09153239,  0.00065104,\n",
       "       -0.25716146, -0.05969238, -0.09700521, -0.02376302,  0.04280599,\n",
       "        0.0082194 , -0.12955729, -0.03857422, -0.0888443 ,  0.13997396,\n",
       "        0.05987549, -0.00716146,  0.05403646,  0.02766927, -0.05598958,\n",
       "        0.04484049, -0.06624349,  0.00341797,  0.09619141, -0.00813802,\n",
       "       -0.03847249,  0.06665039,  0.03971354,  0.06966146, -0.02636719,\n",
       "        0.04614258, -0.02190145,  0.08300781, -0.00097656, -0.02404785,\n",
       "       -0.11572266, -0.14322917, -0.10459391, -0.07063802,  0.01627604,\n",
       "        0.10416667, -0.08837891, -0.02311198, -0.06795247, -0.01920573,\n",
       "       -0.07322184, -0.12434896,  0.0921224 ,  0.05110677, -0.05037435,\n",
       "        0.03434245, -0.13566081,  0.04866536,  0.07210286,  0.06616211,\n",
       "       -0.06559245,  0.01708984,  0.04679362, -0.1648763 , -0.11340332,\n",
       "        0.02083333, -0.17508952,  0.03320312, -0.11442057,  0.05794271,\n",
       "        0.09195964,  0.11776733, -0.06831868, -0.04402669,  0.03918457,\n",
       "       -0.078125  , -0.10172526, -0.00789388,  0.13834635, -0.0608724 ,\n",
       "       -0.16471354, -0.01757812, -0.04915365, -0.02734375,  0.0789388 ,\n",
       "       -0.04947917, -0.02709961, -0.03434245,  0.21679688,  0.05371094,\n",
       "       -0.17333984,  0.04427083,  0.04626465,  0.05794271, -0.07958984,\n",
       "        0.11242676,  0.03190104, -0.10725911,  0.03108724, -0.11311849,\n",
       "        0.0139974 ,  0.09741211,  0.02067057,  0.11995443,  0.15885417])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector representation test\n",
    "vector_representation(\"international corona virus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweets(lines):\n",
    "    \"\"\"\n",
    "    Represents the tweets in a two-dimensional scatter plot.\n",
    "    \"\"\"\n",
    "    word_representations = np.empty((0,300), dtype='f')\n",
    "    word_labels = []\n",
    "\n",
    "    for tweetId in lines:\n",
    "        full_tweet = lines[str(tweetId)]\n",
    "        \n",
    "        tweet = full_tweet[\"full_text\"] # Tweet\n",
    "        vector_rep = vector_representation(tweet)\n",
    "        try:\n",
    "            word_representations = np.append(word_representations, np.array([vector_rep]), axis=0)\n",
    "        except:\n",
    "            continue\n",
    "        word_labels.append(tweetId)\n",
    "\n",
    "        \n",
    "    # find tsne coords for 2 dimensions\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(word_representations)\n",
    "\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    # display scatter plot\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iliasasskali/Library/Python/3.8/lib/python/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/iliasasskali/Library/Python/3.8/lib/python/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing the plot function for 50 tweets, if all tweets are used the label will hide the value and the plot won't look good\n",
    "sliced_lines = dict(itertools.islice(lines.items(), 50))\n",
    "plot_tweets(sliced_lines)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8422209c9efeba716d0afa5c45b8d7468cd6f38f7fdf3cb842165b967294a9ee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
