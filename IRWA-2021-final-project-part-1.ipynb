{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/iliasasskali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets in the dataset: 2399\n",
      "It's International Day for Disaster Risk Reduction\n",
      "\n",
      "#OpenWHO has launched a multi-tiered core curriculum to help equip you with the competencies needed to work within public health emergency response.\n",
      "\n",
      "Start learning today &amp; be #Ready4Response:\n",
      "ðŸ‘‰ https://t.co/hBFFOF0xKL https://t.co/fgZY22RWuS\n",
      "#COVID19 has shown how health emergencies and disasters affect entire communities â€“ especially those with weak health systems, and vulnerable populations like migrants, indigenous peoples, and those living in fragile humanitarian conditions. https://t.co/jpUQpnu0V1\n",
      "It's International Day for Disaster Risk Reduction\n",
      " \n",
      "To better respond to emergencies countries must:\n",
      "âœ… invest in health care systems\n",
      "âœ… achieve gender equity\n",
      "âœ… protect marginalised groups\n",
      "âœ… ensure ready &amp; equitable access to supplies\n",
      " \n",
      "A strong &amp; resilient health system is ðŸ”‘ https://t.co/5NALyjIymp\n"
     ]
    }
   ],
   "source": [
    "docs_path = 'inputs/dataset_tweets_WHO.txt'\n",
    "tweets = []\n",
    "with open(docs_path) as fp:\n",
    "    tweetsJson = json.load(fp)\n",
    "\n",
    "for tweetId in tweetsJson:\n",
    "    tweets.append(tweetsJson[str(tweetId)][\"full_text\"])\n",
    "    \n",
    "print(\"Total number of tweets in the dataset: {}\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @WHOAFRO: Congratulations AlgeriaðŸ‡©ðŸ‡¿!\n",
      "\n",
      "#Algeria is the 16th country in #Africa to reach the milestone of fully vaccinating 10% of its popâ€¦\n",
      "['rt', 'whoafro', 'congratul', 'algeriaðŸ‡©ðŸ‡¿', '#algeria', '16th', 'countri', '#africa', 'reach', 'mileston', 'fulli', 'vaccin', '10', 'popâ€¦']\n"
     ]
    }
   ],
   "source": [
    "def build_terms(line):\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    line = line.lower() ## Transform in lowercase\n",
    "    line = line.split() ## Tokenize the text to get a list of terms\n",
    "    line = [w for w in line if w not in stop_words]  ## eliminate the stopwords (HINT: use List Comprehension)\n",
    "    line = [w.strip(string.punctuation.replace('#', '')) for w in line] ## Remove punctuation\n",
    "    line = [stemmer.stem(w) for w in line] ## perform stemming (HINT: use List Comprehension)\n",
    "    #line = ' '.join(line) ## Join into a single string\n",
    "    return line\n",
    "\n",
    "print(tweets[3])\n",
    "print(build_terms(tweets[3]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
